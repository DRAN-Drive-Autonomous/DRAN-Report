@article{2017arXiv170603762V,
  author = {{Vaswani}, Ashish and {Shazeer}, Noam and {Parmar}, Niki and {Uszkoreit}, Jakob and {Jones}, Llion and {Gomez}, Aidan N. and {Kaiser}, Lukasz and {Polosukhin}, Illia},
  title = "{Attention Is All You Need}",
  journal = {arXiv e-prints},
  keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
  year = 2017,
  month = jun,
  eid = {arXiv:1706.03762},
  pages = {arXiv:1706.03762},
  doi = {10.48550/arXiv.1706.03762},
  archivePrefix = {arXiv},
  eprint = {1706.03762},
  primaryClass = {cs.CL},
  adsurl = {https://ui.adsabs.harvard.edu/abs/2017arXiv170603762V},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@misc{dosovitskiy2021image,
      title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale}, 
      author={Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
      year={2021},
      eprint={2010.11929},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@manual{J3016_202104,
author={On-Road Automated Driving (ORAD) Committee},
title={Taxonomy and Definitions for Terms Related to Driving Automation Systems for On-Road Motor Vehicles},
month={apr},
year={2021},
doi={https://doi.org/10.4271/J3016_202104},
url={https://doi.org/10.4271/J3016_202104},
abstract={This document describes [motor] vehicle driving automation systems that perform part or all of the dynamic driving task (DDT) on a sustained basis. It provides a taxonomy with detailed definitions for six levels of driving automation, ranging from no driving automation (Level 0) to full driving automation (Level 5), in the context of [motor] vehicles (hereafter also referred to as “vehicle” or “vehicles”) and their operation on roadways: Level 0: No Driving Automation Level 1: Driver Assistance Level 2: Partial Driving Automation Level 3: Conditional Driving Automation Level 4: High Driving Automation Level 5: Full Driving Automation These level definitions, along with additional supporting terms and definitions provided herein, can be used to describe the full range of driving automation features equipped on [motor] vehicles in a functionally consistent and coherent manner. “On-road” refers to publicly accessible roadways (including parking areas and private campuses that permit public access) that collectively serve all road users, including cyclists, pedestrians, and users of vehicles with and without driving automation features. The levels apply to the driving automation feature(s) that are engaged in any given instance of on-road operation of an equipped vehicle. As such, although a given vehicle may be equipped with a driving automation system that is capable of delivering multiple driving automation features that perform at different levels, the level of driving automation exhibited in any given instance is determined by the feature(s) that are engaged. This document also refers to three primary actors in driving: the (human) user, the driving automation system, and other vehicle systems and components. These other vehicle systems and components (or the vehicle in general terms) do not include the driving automation system in this model, even though as a practical matter a driving automation system may actually share hardware and software components with other vehicle systems, such as a processing module(s) or operating code. The levels of driving automation are defined by reference to the specific role played by each of the three primary actors in performance of the DDT and/or DDT fallback. “Role” in this context refers to the expected role of a given primary actor, based on the design of the driving automation system in question and not necessarily to the actual performance of a given primary actor. For example, a driver who fails to monitor the roadway during engagement of a Level 1 adaptive cruise control (ACC) system still has the role of driver, even while s/he is neglecting it. Active safety systems, such as electronic stability control (ESC) and automatic emergency braking (AEB), and certain types of driver assistance systems, such as lane keeping assistance (LKA), are excluded from the scope of this driving automation taxonomy because they do not perform part or all of the DDT on a sustained basis, but rather provide momentary intervention during potentially hazardous situations. Due to the momentary nature of the actions of active safety systems, their intervention does not change or eliminate the role of the driver in performing part or all of the DDT, and thus are not considered to be driving automation, even though they perform automated functions. In addition, systems that inform, alert, or warn the driver about hazards in the driving environment are also outside the scope of this driving automation taxonomy, as they neither automate part or all of the DDT, nor change the driver’s role in performance of the DDT (see 8.13). It should be noted, however, that crash avoidance features, including intervention-type active safety systems, may be included in vehicles equipped with driving automation systems at any level. For automated driving system (ADS) features (i.e., Levels 3 to 5) that perform the complete DDT, crash mitigation and avoidance capability is part of ADS functionality (see also 8.13).}
}

@misc{hendrycks2020gaussian,
      title={Gaussian Error Linear Units (GELUs)}, 
      author={Dan Hendrycks and Kevin Gimpel},
      year={2020},
      eprint={1606.08415},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{ba2016layer,
      title={Layer Normalization}, 
      author={Jimmy Lei Ba and Jamie Ryan Kiros and Geoffrey E. Hinton},
      year={2016},
      eprint={1607.06450},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}
@misc{fujimoto2019benchmarking,
      title={Benchmarking Batch Deep Reinforcement Learning Algorithms}, 
      author={Scott Fujimoto and Edoardo Conti and Mohammad Ghavamzadeh and Joelle Pineau},
      year={2019},
      eprint={1910.01708},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{yang2017midinet,
      title={MidiNet: A Convolutional Generative Adversarial Network for Symbolic-domain Music Generation}, 
      author={Li-Chia Yang and Szu-Yu Chou and Yi-Hsuan Yang},
      year={2017},
      eprint={1703.10847},
      archivePrefix={arXiv},
      primaryClass={cs.SD}
}
@ARTICLE{8478136,
  author={Yang, Libin and Zheng, Yu and Cai, Xiaoyan and Dai, Hang and Mu, Dejun and Guo, Lantian and Dai, Tao},
  journal={IEEE Access}, 
  title={A LSTM Based Model for Personalized Context-Aware Citation Recommendation}, 
  year={2018},
  volume={6},
  number={},
  pages={59618-59627},
  doi={10.1109/ACCESS.2018.2872730}}
@INPROCEEDINGS{8540720,
  author={Teban, Teodor-Adrian and Precup, Radu-Emil and Lunca, Elena-Cristina and Albu, Adriana and Bojan-Dragos, Claudia-Adina and Petriu, Emil M.},
  booktitle={2018 22nd International Conference on System Theory, Control and Computing (ICSTCC)}, 
  title={Recurrent Neural Network Models for Myoelectricbased Control of a Prosthetic Hand}, 
  year={2018},
  volume={},
  number={},
  pages={603-608},
  doi={10.1109/ICSTCC.2018.8540720}}
